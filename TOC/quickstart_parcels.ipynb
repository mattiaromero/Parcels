{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from operator import attrgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize \n",
    "import cartopy.crs as ccrs  \n",
    "\n",
    "import parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WrapLongitudeKernel(particle, fieldset, time):\n",
    "    if particle.lon > 180:\n",
    "        particle.dlon = -360\n",
    "    elif particle.lon < -180:\n",
    "        particle.dlon = 360\n",
    "\n",
    "def ConvertParticlesTo360(particle, fieldset, time):\n",
    "    if particle.lon < 0:\n",
    "        particle.lon += 360  # Shift to 0-360 range\n",
    "\n",
    "def ConvertParticlesTo180(particle, fieldset, time):\n",
    "    if particle.lon > 180:\n",
    "        particle.lon -= 360  # Shift back to -180,180 range\n",
    "\n",
    "def DeleteParticle(particle, fieldset, time):\n",
    "    particle.delete()  # Remove particle from the simulation\n",
    "\n",
    "class DrifterParticle(parcels.JITParticle):\n",
    "    age = parcels.Variable(\"age\", dtype=np.float32, initial=0, to_write=True)  \n",
    "    drifter_id = parcels.Variable(\"drifter_id\", dtype=np.float32, to_write=True) \n",
    "\n",
    "def Age(particle, fieldset, time):\n",
    "    particle.age += particle.dt / 3600 # in hours\n",
    "\n",
    "def run_parcels_test(model: str, filenames: dict, variables: dict, dimensions: dict, indices: dict, drifter_df: pd.DataFrame, T: int, dt: int, savet: int, ):\n",
    "    \n",
    "    # QC \n",
    "    print(\"QC:\")\n",
    "\n",
    "    if model == \"AMPHITRITE\":\n",
    "        model_xr = xr.open_dataset(filenames.get(\"U\")[0]) \n",
    "    else: \n",
    "        model_xr = xr.open_dataset(glob.glob(filenames.get(\"U\"))[0]) \n",
    " \n",
    "    for attr in model_xr[variables.get(\"U\")].attrs:\n",
    "        print(attr, \":\", model_xr[variables.get(\"U\")].attrs[attr])\n",
    "\n",
    "    for attr in model_xr.attrs:\n",
    "        print(attr, \":\", model_xr.attrs[attr])\n",
    "\n",
    "    if model == \"ROMS\":\n",
    "        fieldset = parcels.FieldSet.from_mitgcm(filenames, variables, dimensions, indices, allow_time_extrapolation=True)\n",
    "    else: \n",
    "        fieldset = parcels.FieldSet.from_netcdf(filenames, variables, dimensions, indices, allow_time_extrapolation=True)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Dataset size:\", len(fieldset.U.grid.lon)*len(fieldset.U.grid.lat)*len(fieldset.U.grid.time)) \n",
    "    print(\"Domain:\", fieldset.U.grid.lon.min(), fieldset.U.grid.lon.max(),  fieldset.U.grid.lat.min(), fieldset.U.grid.lat.max())\n",
    "    print(\"\")\n",
    "\n",
    "    # Define a new particleclass with Variable 'age' with initial value 0.\n",
    "    # AgeParticle = parcels.JITParticle.add_variable(parcels.Variable(\"age\", initial=0))\n",
    "\n",
    "    pset = parcels.ParticleSet.from_list(\n",
    "        fieldset=fieldset,\n",
    "        pclass=DrifterParticle,\n",
    "        lon=drifter_df[\"lon\"].values,\n",
    "        lat=drifter_df[\"lat\"].values,\n",
    "        time=drifter_df[\"time\"].values,\n",
    "        drifter_id=drifter_df[\"id_nr\"].values.astype(np.float32)\n",
    "    )\n",
    "\n",
    "    output_file = pset.ParticleFile(\n",
    "        name=f\"{model}Particles.zarr\", outputdt=timedelta(hours=savet)\n",
    "    )\n",
    "\n",
    "    if model ==\"HYCOM\":\n",
    "        kernels = [Age, ConvertParticlesTo360, parcels.AdvectionRK4]\n",
    "\n",
    "        pset.execute(\n",
    "            kernels, # pset.Kernel(ConvertParticlesTo360) + parcels.AdvectionRK4,\n",
    "            runtime=timedelta(hours=T),\n",
    "            dt=timedelta(hours=dt),\n",
    "            output_file=output_file\n",
    "        )\n",
    "\n",
    "        # Convert back before saving output\n",
    "        #pset.execute(\n",
    "            # pset.Kernel(ConvertParticlesTo180),\n",
    "            # runtime=timedelta(seconds=0),  # Just apply conversion\n",
    "            # dt=timedelta(seconds=0)\n",
    "        # )\n",
    "\n",
    "        for particle in pset:\n",
    "            if particle.lon > 180:\n",
    "                particle.lon -= 360  # Convert from 0-360 to -180,180\n",
    "    \n",
    "    else:\n",
    "        kernels = [Age, parcels.AdvectionRK4]\n",
    "\n",
    "        pset.execute(\n",
    "            kernels, # parcels.AdvectionRK4,\n",
    "            runtime=timedelta(hours=T),\n",
    "            dt=timedelta(hours=dt),\n",
    "            output_file=output_file\n",
    "        )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ics_df = tracks_df.set_index(\"time\")\n",
    "non_numerical_cols = ics_df.select_dtypes(exclude=\"number\")\n",
    "\n",
    "filled_non_numerical = (\n",
    "    non_numerical_cols.groupby(\"id\")\n",
    "    .apply(lambda group: group.resample(\"1D\").ffill())\n",
    ")\n",
    "ics_df = ics_df.groupby(\"id\").resample(\"1D\").interpolate().drop(columns=[\"id\",\"drogue\"]).reset_index()\n",
    "ics_df[\"segment_id\"] = ics_df[\"segment_id\"].astype(int)\n",
    "ics_df = ics_df.merge(filled_non_numerical.drop(columns=[\"id\"]).reset_index(), how=\"left\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP 1C - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load drifter tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load drifter tracks \n",
    "drifter_folder = r\"Y:/PROJECTS/DRIFTERS/data/qc_tdsi_6h_2\"\n",
    "files = glob.glob(f\"{drifter_folder}/*.csv\")\n",
    "\n",
    "drifter_df = pd.DataFrame()\n",
    "for file in files: \n",
    "    df = pd.read_csv(file)  \n",
    "    drifter_df = pd.concat([drifter_df, df], ignore_index=True)  \n",
    "\n",
    "drifter_df.rename(columns={\"longitude\": \"lon\", \"latitude\": \"lat\"}, inplace=True)\n",
    "drifter_df = drifter_df[drifter_df[\"deployed\"] != False]\n",
    "drifter_df.drop(columns=\"deployed\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, e, s, n = drifter_df.lon.min(), drifter_df.lon.max(), drifter_df.lat.min(), drifter_df.lat.max()\n",
    "w, e, s, n = int(w), int(e), int(s), int(n)\n",
    "\n",
    "tstart, tend = drifter_df.time.min(), drifter_df.time.max()\n",
    "\n",
    "d_nr = drifter_df.id.count()\n",
    "\n",
    "print(\"Number of drifters:\", d_nr)\n",
    "print(\"Time range:\", tstart, tend)\n",
    "print(\"W, E, S, N:\", [w, e, s, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, e, s, n = -160, -125, 20, 40\n",
    "tstart = '2022-01-01'\n",
    "tend = '2022-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter \n",
    "wesn = (drifter_df.lon > w) & (drifter_df.lon < e) & (drifter_df.lat > s) & (drifter_df.lat < n)\n",
    "time = (drifter_df.time >= tstart) & (drifter_df.time <= tend)\n",
    "drifter_df[\"time\"] = pd.to_datetime(drifter_df[\"time\"])\n",
    "tracks_df = drifter_df[time & wesn].reset_index(drop=True)\n",
    "tracks_df[\"id_nr\"] = tracks_df.groupby(\"id\").ngroup()\n",
    "\n",
    "ics_df = tracks_df.groupby(\"id_nr\", group_keys=False).apply(lambda x: x.iloc[::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, e, s, n = ics_df.lon.min(), ics_df.lon.max(), ics_df.lat.min(), ics_df.lat.max()\n",
    "w, e, s, n = int(w), int(e), int(s), int(n)\n",
    "\n",
    "tstart, tend = ics_df.time.min(), ics_df.time.max()\n",
    "\n",
    "d_nr = ics_df.id_nr.max()\n",
    "\n",
    "print(\"Time range: \", tstart, tend)\n",
    "print(\"W, E, S, N:\", [w, e, s, n])\n",
    "print(\"Number of drifters:\", d_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ics_df = ics_df.groupby(\"id\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "scatter = ax.scatter(ics_df.lon, ics_df.lat, s=10, c=ics_df[\"id_nr\"], cmap=\"tab20c\", edgecolor=\"k\")\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax, orientation='horizontal', pad=0.05)\n",
    "cbar.set_label('Drifter ID', fontsize=12)\n",
    "\n",
    "ax.set_title(f\"Map of Initial Conditions ({ics_df.time.iloc[0].strftime('%Y-%m-%d')} - {ics_df.time.iloc[-1].strftime('%Y-%m-%d')})\", fontsize=16)\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.coastlines(resolution='110m', color='black', linewidth=1)\n",
    "ax.set_xlabel(\"Longitude\", fontsize=14)\n",
    "ax.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax.set_extent([ics_df.lon.min(), ics_df.lon.max(), ics_df.lat.min(), ics_df.lat.max()], crs=ccrs.PlateCarree())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load OGCMs\n",
    "\n",
    "Amphitrite training period: 2018-2021 and 08/2023-02/2024 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources <br>\n",
    "Grid:  <br>\n",
    "https://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/build/ch05s06.html <br> \n",
    "https://www.oc.nps.edu/nom/modeling/grids.html <br> \n",
    "<br> \n",
    "Conventions: <br> \n",
    "http://cfconventions.org/cf-conventions/v1.6.0/cf-conventions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = int((tracks_df.time.max() - tracks_df.time.min()).total_seconds()/3600) # 7*24 \n",
    "dt = 1\n",
    "savet = 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLOBCURRENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"F:/ADVECTOR/metocean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"GLOBCURRENT\"\n",
    "\n",
    "filenames = {\n",
    "    \"U\": f\"{dataset_folder}/globcurrent/uo_*.nc\",\n",
    "    \"V\": f\"{dataset_folder}/globcurrent/vo_*.nc\"\n",
    "}\n",
    "variables = {\n",
    "    \"U\": \"uo\",\n",
    "    \"V\": \"vo\",\n",
    "}\n",
    "\n",
    "dimensions = {\"time\": \"time\", \"lat\": \"latitude\", \"lon\": \"longitude\", \"time\": \"time\"}\n",
    "\n",
    "indices = {'lon': range(0,4*60), 'lat': range(4*105,4*135)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parcels_test(model, filenames, variables, dimensions, indices, ics_df, T, dt, savet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: ChatGPT \n",
    "\n",
    "# Load dataset\n",
    "ds = xr.open_zarr(\"GLOBCURRENTParticles.zarr\") \n",
    "tracks = tracks_df[tracks_df.id_nr < 10]\n",
    "\n",
    "# Mask dataset for selected drifters\n",
    "ds = ds.where(ds.drifter_id.isin(tracks.id_nr.unique()).compute(), drop=True)\n",
    "drifter_ids = tracks.id_nr.unique()\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Define colormap\n",
    "cmap_id = plt.get_cmap(\"tab20c\", len(drifter_ids))  # Unique color per drifter ID\n",
    "norm = Normalize(vmin=drifter_ids.min(), vmax=drifter_ids.max())  # Normalize ID values for color mapping\n",
    "\n",
    "# Scatter plot for each drifter\n",
    "sc = None  # Placeholder for colorbar reference\n",
    "for i, (id, drifter) in enumerate(tracks.groupby(\"id_nr\")): \n",
    "    track = drifter  # No need to redefine it with filtering again\n",
    "    sc = ax.scatter(track.lon, track.lat, c=[id] * len(track), cmap=cmap_id, norm=norm, s=50, edgecolor=\"k\", marker=\"v\", zorder=0)\n",
    "\n",
    "    # Filter dataset for particle positions\n",
    "    mask = ds.drifter_id == id\n",
    "    age_mask = (ds.drifter_id == id) & (ds.age == 1)\n",
    "\n",
    "    if len(ds.lon.values[np.where(mask.values)]) == 0:\n",
    "        print(f\"Missing particle for ID {id}\")\n",
    "\n",
    "    ax.scatter(ds.lon.values[age_mask], ds.lat.values[age_mask], color=cmap_id(i), s=50, marker=\"s\", zorder=2)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(sc, ax=ax, orientation='horizontal', pad=0.05)\n",
    "cbar.set_label('Drifter ID', fontsize=12)\n",
    "\n",
    "# Labels and styling\n",
    "ax.set_title(f\"Sample of Drifter Tracks vs Initial Conditions ({tracks_df.time.iloc[0].strftime('%Y-%m-%d')} - {tracks_df.time.iloc[-1].strftime('%Y-%m-%d')})\", fontsize=16)\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.coastlines(resolution='110m', color='black', linewidth=1)\n",
    "ax.set_xlabel(\"Longitude\", fontsize=14)\n",
    "ax.set_ylabel(\"Latitude\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\"GLOBCURRENTParticles.zarr\") \n",
    "\n",
    "tracks = tracks_df[tracks_df.id_nr < 10]\n",
    "\n",
    "ds = xr.open_zarr(f\"GLOBCURRENTParticles.zarr\")\n",
    "drifter_mask = ds.drifter_id.isin(tracks.id_nr.unique()).compute()\n",
    "ds = ds.where(drifter_mask, drop=True)\n",
    "\n",
    "drifter_ids = tracks.id_nr.unique() # np.unique(ds.drifter_id.values)  \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "cmap_id = plt.get_cmap(\"tab20c\", len(drifter_ids))  # Unique color per drifter ID\n",
    "cmap_age = plt.get_cmap(\"viridis\")  # Age gradient\n",
    "\n",
    "for i, (id, drifter) in enumerate(tracks.groupby(\"id_nr\")): \n",
    "    # print(f\"{i}/{len(drifter_ids)}\")\n",
    "\n",
    "    track = tracks[tracks[\"id_nr\"] == id]\n",
    "    ax.scatter(track.lon, track.lat, color=cmap_id(i), s= 50, edgecolor=\"k\", marker=\"v\", zorder = 0)\n",
    "        \n",
    "    drifter_mask = ds.drifter_id == id \n",
    "    age_mask = (ds.drifter_id == id) & (ds.age == 1)\n",
    "    mask_indices = np.where(drifter_mask.values)\n",
    "\n",
    "    if len(ds.lon.values[mask_indices]) == 0:\n",
    "        print(\"Missing particle\")\n",
    "\n",
    "    # ax.scatter(ds.lon.values[mask_indices], ds.lat.values[mask_indices], color=cmap_id(i), alpha=0.5, s= ds.age.values[mask_indices]/10, zorder = 1)\n",
    "    ax.scatter(ds.lon.values[age_mask], ds.lat.values[age_mask], color=cmap_id(i), s= 50, marker = \"s\", zorder = 2)\n",
    "\n",
    "# cbar = plt.colorbar(scatter, ax=ax, orientation='horizontal', pad=0.05)\n",
    "# cbar.set_label('Drifter ID', fontsize=12)\n",
    "\n",
    "ax.set_title(f\"Sample of Drifter Tracks vs Initial Conditions ({ics_df.time.iloc[0].strftime('%Y-%m-%d')} - {ics_df.time.iloc[-1].strftime('%Y-%m-%d')})\", fontsize=16)\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.coastlines(resolution='110m', color='black', linewidth=1)\n",
    "ax.set_xlabel(\"Longitude\", fontsize=14)\n",
    "ax.set_ylabel(\"Latitude\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLORYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"GLORYS\"\n",
    "\n",
    "filenames = {\n",
    "    \"U\": f\"{dataset_folder}/nemo/nemo_hourly_operational_u_*.nc\",\n",
    "    \"V\": f\"{dataset_folder}/nemo/nemo_hourly_operational_v_*.nc\",\n",
    "}\n",
    "\n",
    "variables = {\"U\": \"uo\", \"V\": \"vo\"}\n",
    "\n",
    "dimensions = {\"time\": \"time\", \"lon\": \"longitude\", \"lat\": \"latitude\"}\n",
    "\n",
    "indices = {\"lon\": range(0,12*60), \"lat\": range(12*95,12*125)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parcels_test(model, filenames, variables, dimensions, indices, ics_df, T, dt, savet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"SMOC\"\n",
    "\n",
    "filenames = {\n",
    "    \"U\": f\"{dataset_folder}/nemo_tot/nemo_hourly_operational_utot_*.nc\",\n",
    "    \"V\": f\"{dataset_folder}/nemo_tot/nemo_hourly_operational_vtot_*.nc\",\n",
    "}\n",
    "\n",
    "variables = {\"U\": \"utotal\", \"V\": \"vtotal\"}\n",
    "\n",
    "dimensions = {\"time\": \"time\", \"lon\": \"longitude\", \"lat\": \"latitude\"}\n",
    "\n",
    "indices = {\"lon\": range(0,12*60), \"lat\": range(12*95,12*125)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parcels_test(model, filenames, variables, dimensions, indices, ics_df, T, dt, savet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYCOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for file in glob.glob(f\"{dataset_folder}/hycom/hycom_operational_*.nc\"):\n",
    "    ds = xr.open_dataset(file)\n",
    "    ds[\"lon\"] = ((ds[\"lon\"] + 180) % 360) - 180\n",
    "    ds.attrs[\"geospatial_lon_min\"] = -180.0  # Convert from 0.0\n",
    "    ds.attrs[\"geospatial_lon_max\"] = 179.92  # Convert from 359.92\n",
    "    ds = ds.sortby(\"lon\")\n",
    "    ds.to_netcdf(file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"HYCOM\"\n",
    "\n",
    "filenames = {\"U\": f\"{dataset_folder}/hycom/hycom_operational_*.nc\",\n",
    "             \"V\": f\"{dataset_folder}/hycom/hycom_operational_*.nc\",\n",
    "            }\n",
    "\n",
    "variables = {\"U\": \"water_u\", \"V\": \"water_v\"}\n",
    "\n",
    "dimensions = {\"time\": \"time\", \"lon\": \"lon\", \"lat\": \"lat\"}\n",
    "\n",
    "indices = {'lon': range(int(180*12.5), int(240*12.5)), 'lat': range(int(25*95),int(25*125))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parcels_test(model, filenames, variables, dimensions, indices, ics_df, T, dt, savet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "roms = xr.open_dataset(glob.glob(f\"{dataset_folder}/roms/hycom_20220101.nc\")[0])\n",
    "roms.isel(time=0, depth=0).u.plot(vmin=-1)\n",
    "roms = xr.open_dataset(glob.glob(f\"{dataset_folder}/roms/nemo_20220101.nc\")[0])\n",
    "roms.isel(time=0, depth=0).u.plot(vmin=-1)\n",
    "\n",
    "print(np.shape(roms.u))\n",
    "print(np.shape(roms.v))\n",
    "print(np.shape(roms.h))\n",
    "\n",
    "nind = 3\n",
    "plt.scatter(roms.lon_u.values[:nind, :nind], roms.lat_u.values[:nind, :nind], c =\"r\", label = \"U grid\")\n",
    "plt.scatter(roms.lon_v.values[:nind, :nind], roms.lat_v.values[:nind, :nind], c =\"b\", label = \"V grid\")\n",
    "plt.scatter(roms.lon_rho.values[:nind, :nind], roms.lat_rho.values[:nind, :nind], c =\"k\", label = \"C (rho) grid\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ROMS\"\n",
    "\n",
    "filenames = {\"U\": f\"{dataset_folder}/roms/test134cars_npo0.08_07e_2022*.nc\", \n",
    "             \"V\": f\"{dataset_folder}/roms/test134cars_npo0.08_07e_2022*.nc\"\n",
    "}\n",
    "\n",
    "variables = {\"U\": \"u\", \"V\": \"v\"}\n",
    "\n",
    "# Note that all variables need the same dimensions in a C-Grid\n",
    "c_grid_dimensions = {\n",
    "    \"lon\": \"lon_rho\",\n",
    "    \"lat\": \"lat_rho\",\n",
    "    \"time\": \"ocean_time\",\n",
    "}\n",
    "\n",
    "dimensions = {\n",
    "    \"U\": c_grid_dimensions,\n",
    "    \"V\": c_grid_dimensions,\n",
    "}\n",
    "\n",
    "indices = {\"lon\": range(0,600), \"lat\": range(0,375)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parcels_test(model, filenames, variables, dimensions, indices, ics_df, T, dt, savet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amphitrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"AMPHITRITE\"\n",
    "\n",
    "paths = []\n",
    "\n",
    "folders = glob.glob(f\"{dataset_folder}/amphitrite/*\")\n",
    "for folder in folders: \n",
    "    paths.append(glob.glob(f\"{folder}/*.nc\")[0])\n",
    "\n",
    "filenames = {\"U\": paths, \n",
    "             \"V\": paths\n",
    "}\n",
    "\n",
    "variables = {\"U\": \"u\", \"V\": \"v\"}\n",
    "\n",
    "dimensions = {\"time\": \"time\", \"lon\": \"longitude\", \"lat\": \"latitude\"}\n",
    "\n",
    "indices = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parcels_test(model, filenames, variables, dimensions, indices, ics_df, T, dt, savet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\"GLOBCURRENT\", \"GLORYS\", \"SMOC\", \"HYCOM\", \"ROMS\", \"AMPHITRITE\"]\n",
    "# colors = [\"purple\", \"red\", \"orange\", \"blue\", \"cyan\", \"green\"]\n",
    "\n",
    "models = [\"GLOBCURRENT\", \"GLORYS\", \"SMOC\", \"HYCOM\", \"AMPHITRITE\"]\n",
    "colors = [\"purple\", \"red\", \"orange\", \"blue\", \"green\"]\n",
    "\n",
    "# Create a map with Cartopy GeoAxes\n",
    "fig, axs = plt.subplots(2,1, figsize=(20, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "for ax in axs:\n",
    "    # Plot the trajectories for each model\n",
    "    for k, model in zip(colors, models):\n",
    "        ds = xr.open_zarr(f\"{model}Particles.zarr\")\n",
    "        for \n",
    "        ds.traj.plot(ax=ax, label=model, color=k, alpha=0.7)\n",
    "\n",
    "    # Plot drifter samples (scatter plot for each drifter group)\n",
    "    # Track whether the drifter label has been used already\n",
    "    label_used = False\n",
    "    for id, drifter in tracks_df.groupby(\"id\"): \n",
    "        ax.plot(drifter.lon, drifter.lat, 'k', linewidth=2, label=\"Drifter Sample\" if not label_used else \"\")\n",
    "        label_used = True  # Ensure the label is used only once\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.set_title(\"Particle Trajectories and Drifter Samples (2022-01-01 to 2022-01-07)\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Improve the legend (remove duplicate labels)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "\n",
    "axs[0].legend(by_label.values(), by_label.keys())\n",
    "\n",
    "axs[1].set_xlim(-140,-145)\n",
    "axs[1].set_ylim(30,35)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parcels.timer.root = parcels.timer.Timer(\"root\")##\n",
    "# parcels.timer.fieldset = parcels.timer.Timer(\"fieldset creation\", parent=parcels.timer.root)\n",
    "# parcels.timer.fieldset.stop()\n",
    "# # parcels.timer.root.stop()\n",
    "# parcels.timer.root.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\"XXXParticles.zarr\")\n",
    "ds.traj.plot(margin=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling a Field with Particles\n",
    "\n",
    "https://archimer.ifremer.fr/doc/00157/26792/24888.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this flow does not depend on time, we need to set allow_time_extrapolation=True when reading in the fieldset\n",
    "\n",
    "example_dataset_folder = parcels.download_example_dataset(\"Peninsula_data\")\n",
    "fieldset = parcels.FieldSet.from_parcels(\n",
    "    f\"{example_dataset_folder}/peninsula\",\n",
    "    extra_fields={\"P\": \"P\"},\n",
    "    allow_time_extrapolation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleParticle = parcels.JITParticle.add_variable(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = parcels.ParticleSet.from_line(\n",
    "    fieldset=fieldset,\n",
    "    pclass=SampleParticle,\n",
    "    start=(3000, 3000),\n",
    "    finish=(3000, 46000),\n",
    "    size=5,\n",
    "    time=0,\n",
    ")\n",
    "\n",
    "plt.contourf(fieldset.P.grid.lon, fieldset.P.grid.lat, fieldset.P.data[0, :, :])\n",
    "plt.xlabel(\"Zonal distance [m]\")\n",
    "plt.ylabel(\"Meridional distance [m]\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.plot(pset.lon, pset.lat, \"ko\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SampleP(particle, fieldset, time):\n",
    "    \"\"\"Custom function that samples fieldset.P at particle location\"\"\"\n",
    "    particle.p = fieldset.P[time, particle.depth, particle.lat, particle.lon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pset.ParticleFile(\n",
    "    name=\"PeninsulaPressure.zarr\", outputdt=timedelta(hours=1)\n",
    ")\n",
    "pset.execute(\n",
    "    [parcels.AdvectionRK4, SampleP],  # list of kernels to be executed\n",
    "    runtime=timedelta(hours=20),\n",
    "    dt=timedelta(minutes=5),\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\"PeninsulaPressure.zarr\")\n",
    "\n",
    "plt.contourf(fieldset.P.grid.lon, fieldset.P.grid.lat, fieldset.P.data[0, :, :])\n",
    "plt.xlabel(\"Zonal distance [m]\")\n",
    "plt.ylabel(\"Meridional distance [m]\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.scatter(ds.lon, ds.lat, c=ds.p, s=30, cmap=\"viridis\", edgecolors=\"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating distance travelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_write to write in output file\n",
    "\n",
    "extra_vars = [\n",
    "    parcels.Variable(\"distance\", initial=0.0, dtype=np.float32),\n",
    "    parcels.Variable(\n",
    "        \"prev_lon\", dtype=np.float32, to_write=False, initial=attrgetter(\"lon\")\n",
    "    ),\n",
    "    parcels.Variable(\n",
    "        \"prev_lat\", dtype=np.float32, to_write=False, initial=attrgetter(\"lat\")\n",
    "    ),\n",
    "]\n",
    "\n",
    "DistParticle = parcels.JITParticle.add_variables(extra_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TotalDistance(particle, fieldset, time):\n",
    "    \"\"\"Calculate the distance in latitudinal direction\n",
    "    (using 1.11e2 kilometer per degree latitude)\"\"\"\n",
    "    lat_dist = (particle.lat - particle.prev_lat) * 1.11e2\n",
    "    lon_dist = (\n",
    "        (particle.lon - particle.prev_lon)\n",
    "        * 1.11e2\n",
    "        * math.cos(particle.lat * math.pi / 180)\n",
    "    )\n",
    "    # Calculate the total Euclidean distance travelled by the particle\n",
    "    particle.distance += math.sqrt(math.pow(lon_dist, 2) + math.pow(lat_dist, 2))\n",
    "\n",
    "    # Set the stored values for next iteration\n",
    "    particle.prev_lon = particle.lon\n",
    "    particle.prev_lat = particle.lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset_folder = parcels.download_example_dataset(\"GlobCurrent_example_data\")\n",
    "filenames = {\n",
    "    \"U\": f\"{example_dataset_folder}/20*.nc\",\n",
    "    \"V\": f\"{example_dataset_folder}/20*.nc\",\n",
    "}\n",
    "variables = {\n",
    "    \"U\": \"eastward_eulerian_current_velocity\",\n",
    "    \"V\": \"northward_eulerian_current_velocity\",\n",
    "}\n",
    "dimensions = {\"lat\": \"lat\", \"lon\": \"lon\", \"time\": \"time\"}\n",
    "fieldset = parcels.FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "pset = parcels.ParticleSet.from_line(\n",
    "    fieldset=fieldset, pclass=DistParticle, size=5, start=(28, -33), finish=(30, -33)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset.execute(\n",
    "    [parcels.AdvectionRK4, TotalDistance],  # list of kernels to be executed\n",
    "    runtime=timedelta(days=6),\n",
    "    dt=timedelta(minutes=5),\n",
    "    output_file=pset.ParticleFile(\n",
    "        name=\"GlobCurrentParticles_Dist.zarr\", outputdt=timedelta(hours=1)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([p.distance for p in pset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parcels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
